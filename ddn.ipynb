{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from ddn_config import *\n",
    "from ddn_etl_utils import *\n",
    "from etl_es import *\n",
    "import datetime\n",
    "import hashlib\n",
    "\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2018-07-27 19:00:00'\n",
    "end_time = '2018-07-27 19:40:59'\n",
    "\n",
    "read_label = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vpn_ip(ip):\n",
    "    if '172.' in ip:\n",
    "        return True\n",
    "    return False\n",
    "vpn_ip_udf = udf(vpn_ip, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_data = read_es(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_data['conn'].filter(vpn_ip_udf('`id.orig_h`'))\\\n",
    "#         .select('`id.orig_h`').distinct().toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_schema = ['type', 'node_id', 'node_ip', 'node_attr', 'ddn_id']\n",
    "edge_schema = ['from_id', 'to_id', 'proto', 'ddn_id', 'application', 'direction', 'total_bytes']\n",
    "\n",
    "# the schema for matching labels with existing ddn\n",
    "# category supports : 1. user; 2. application\n",
    "# role: will be used as ddn id\n",
    "# ids: for user, this list is ip list, for application, this list will be application key works within URI\n",
    "label_schema = ['category', 'role', 'ids']\n",
    "\n",
    "web_portal = ['192.168.7.100', '192.168.8.100']\n",
    "sql_portal = ['192.168.8.74', '192.168.8.155']\n",
    "\n",
    "#TODO: figure out an algorithm to detect multi-homed machines\n",
    "multi_homed_machine = [['192.168.7.100', \n",
    "                        '192.168.8.100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 44, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\nStopIteration\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nRuntimeError: generator raised StopIteration\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\nStopIteration\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nRuntimeError: generator raised StopIteration\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-83f9297d831b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mweb_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# web_nodes.collect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# web_nodes.toDF()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \"\"\"\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             raise ValueError(\"The first row in RDD is empty, \"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \"\"\"\n\u001b[0;32m-> 1393\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 44, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\nStopIteration\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nRuntimeError: generator raised StopIteration\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\nStopIteration\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/Users/yuming/spark-2.3.1-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\nRuntimeError: generator raised StopIteration\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "multi_homed_machine_dict = {'192.168.7.100': 'web',\n",
    "                            '192.168.8.100': 'web'}\n",
    "rows = []\n",
    "for ip in web_portal:\n",
    "    row_dict = {}\n",
    "    row_dict['type'] = 'application'\n",
    "    row_dict['node_id'] = multi_homed_machine_dict[ip]\n",
    "    row_dict['node_ip'] = ip\n",
    "    row_dict['node_attr'] = ' '\n",
    "    row_dict['ddn_id'] = 'default_pii'\n",
    "    rows.append(Row(**row_dict))\n",
    "    \n",
    "rows\n",
    "sc = spark.sparkContext\n",
    "web_nodes = sc.parallelize(rows).toDF()\n",
    "# web_nodes.collect()\n",
    "# web_nodes.toDF()\n",
    "# .toDF().select(node_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>node_attr</th>\n",
       "      <th>ddn_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>application</td>\n",
       "      <td>web</td>\n",
       "      <td>192.168.7.100</td>\n",
       "      <td></td>\n",
       "      <td>default_pii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>application</td>\n",
       "      <td>web</td>\n",
       "      <td>192.168.8.100</td>\n",
       "      <td></td>\n",
       "      <td>default_pii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type node_id        node_ip node_attr       ddn_id\n",
       "0  application     web  192.168.7.100            default_pii\n",
       "1  application     web  192.168.8.100            default_pii"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_nodes.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_ip = web_portal + sql_portal\n",
    "interested_ip\n",
    "def in_list(ip):\n",
    "    return ip in interested_ip\n",
    "in_list_udf = udf(in_list, BooleanType())\n",
    "\n",
    "def multihomed_ip(ip):\n",
    "    for machine in multi_homed_machine:\n",
    "        if ip in machine:\n",
    "            return ','.join(machine)\n",
    "    return None\n",
    "multihomed_ip_udf = udf(multihomed_ip, StringType())\n",
    "\n",
    "def filter_intenal_ip(ip):\n",
    "    if ip is None:\n",
    "        return False\n",
    "    return '192.168' in ip\n",
    "filter_internal_ip_udf = udf(filter_intenal_ip, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resolution = 300 # in secs, 5min\n",
    "def float_to_datetime(seconds):\n",
    "    if seconds is None:\n",
    "        return 0.0\n",
    "    return float(seconds)\n",
    "sec_to_dt_udf = udf(float_to_datetime, DoubleType())\n",
    "\n",
    "def ts_to_float(str):\n",
    "    from dateutil.parser import parse\n",
    "    if str is None:\n",
    "        return 0.0\n",
    "    dt = parse(str)\n",
    "    return dt.timestamp()\n",
    "ts_to_float_udf = udf(ts_to_float, DoubleType())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GET http://192.168.7.15:9200/tds_tds7login/_search?size=10000 [status:404 request:0.004s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading index tds_tds7login error from ES\n",
      "Reading index fuzzy error from ES\n"
     ]
    }
   ],
   "source": [
    "ddn = connect_ddn(start_time = start_time, \n",
    "                  end_time = end_time)\n",
    "ddn = ddn.filter(col('app')!='dns')\\\n",
    "         .repartition(20)\n",
    "from_ddn = ddn.filter(in_list_udf(\"`id.orig_h`\"))\n",
    "to_ddn = ddn.filter(in_list_udf(\"`id.resp_h`\"))\n",
    "interested_ddn = from_ddn.union(to_ddn)\\\n",
    "                         .withColumn('ts_float', ts_to_float_udf('@timestamp'))\\\n",
    "                         .persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98075"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_ddn.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_schema = ['`id.orig_h`', '`id.orig_p`', '`id.resp_h`', '`id.resp_p`', '@timestamp', \n",
    "                     'ts_float', 'app', 'sqlbatch', 'arg', 'cmd', 'uri', 'proto', 'method', \n",
    "                     'orig_bytes', 'resp_bytes', 'uid', 'orig_sum_bytes', 'resp_sum_bytes']\n",
    "interested_ddn.distinct().count()\n",
    "\n",
    "# this will be used to derive \"edge\"\n",
    "all_connections = interested_ddn.select(connection_schema).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the following block calculate db host, talbes, and column names\n",
    "SQL_COL = 'sql_query' # when sqlbatch works, update here\n",
    "def fill_sql_query(sqlbatch, arg):\n",
    "    if sqlbatch is None:\n",
    "        return arg\n",
    "    return sqlbatch\n",
    "fill_sql_query_udf = udf(fill_sql_query, StringType())\n",
    "\n",
    "def extract_table_column_sql(sql):\n",
    "    tables = []\n",
    "    columns = []\n",
    "    if sql is None:\n",
    "        return (tables, columns)\n",
    "    sql = sql.lower()\n",
    "    from_split = sql.split('from ')\n",
    "    if len(from_split) == 2:\n",
    "        where_split = from_split[1].split(' where ')\n",
    "        tables.append(where_split[0])\n",
    "        col_split = where_split[1].split(' =')\n",
    "        columns.append(col_split[0])\n",
    "    insert_split = sql.split('insert into ')\n",
    "    if len(insert_split) == 2:\n",
    "        tables.append(insert_split[1].split(' ')[0])\n",
    "        columns.append('*') # all columns\n",
    "    return (tables, columns)\n",
    "\n",
    "def gen_direction(sql, method):\n",
    "    if sql is not None:\n",
    "        sql = sql.lower()\n",
    "        if 'insert into' in sql:\n",
    "            return 'co'\n",
    "        if 'select' in sql:\n",
    "            return 'counter'\n",
    "    if method is not None:\n",
    "        method = method.lower()\n",
    "        if 'post' in method:\n",
    "            return 'co'\n",
    "        if 'get' in method:\n",
    "            return 'counter'\n",
    "    return None\n",
    "gen_direction_udf = udf(gen_direction, StringType())\n",
    "\n",
    "def gen_total_bytes(direction, orig_sum_bytes, resp_sum_bytes):\n",
    "    if orig_sum_bytes is None:\n",
    "        orig_sum_bytes = 0.0\n",
    "    if resp_sum_bytes is None:\n",
    "        resp_sum_bytes = 0.0\n",
    "    def _my_max(a, b):\n",
    "        if a >= b:\n",
    "            return a\n",
    "        return b\n",
    "    if direction is None:\n",
    "        return _my_max(orig_sum_bytes, resp_sum_bytes)\n",
    "    if direction == 'co':\n",
    "        return orig_sum_bytes\n",
    "    return resp_sum_bytes\n",
    "gen_total_bytes_udf = udf(gen_total_bytes, DoubleType())\n",
    "\n",
    "def combine_list_to_set(x, y):\n",
    "    res = set()\n",
    "    res.update(x)\n",
    "    res.update(y)\n",
    "    return res\n",
    "\n",
    "def process_table_col_to_row(pair):\n",
    "    host = pair[0]\n",
    "    table_set = pair[1][0]\n",
    "    col_set = pair[1][1]\n",
    "    table_list = list(table_set)\n",
    "    col_list = list(col_set)\n",
    "    res = {}\n",
    "    res['db_host'] = host\n",
    "    res['tables'] = table_list\n",
    "    res['columns'] = col_list\n",
    "    return Row(**res)\n",
    "    \n",
    "all_connections = all_connections.withColumn(SQL_COL, fill_sql_query_udf('sqlbatch', 'arg'))\\\n",
    "                                 .withColumn('direction', gen_direction_udf(SQL_COL, 'method'))\\\n",
    "                                 .withColumn('total_bytes', gen_total_bytes_udf('direction', 'orig_sum_bytes', 'resp_sum_bytes'))\n",
    "db_table_col = all_connections.filter(col(SQL_COL).isNotNull())\\\n",
    "               .rdd.map(lambda row: (row['id.resp_h'], extract_table_column_sql(row[SQL_COL])))\\\n",
    "               .reduceByKey(lambda x, y: (combine_list_to_set(x[0], y[0]), combine_list_to_set(x[1], y[1])))\\\n",
    "               .map(lambda pair: process_table_col_to_row(pair))\\\n",
    "               .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate db node\n",
    "db_map = {\n",
    "    '192.168.8.74' : 'mysql',\n",
    "    '192.168.8.155': 'mssql'\n",
    "    }\n",
    "def generate_db_id(ip):\n",
    "    return db_map[ip]\n",
    "generate_db_id_udf = udf(generate_db_id, StringType())\n",
    "\n",
    "def generate_db_ip(ip):\n",
    "    return ip\n",
    "generate_db_ip_udf = udf(generate_db_ip, StringType())\n",
    "\n",
    "def generate_db_attr(columns, tables):\n",
    "    res = {}\n",
    "    res['columns'] = columns\n",
    "    res['tables'] = tables\n",
    "    return json.dumps(res)\n",
    "generate_db_attr_udf = udf(generate_db_attr, StringType())\n",
    "\n",
    "# node_schema = ['type', 'node_id', 'node_ip', 'node_attr', 'ddn_id']\n",
    "db_node = db_table_col.withColumn('type', lit('database'))\\\n",
    "            .withColumn('node_id', generate_db_id_udf('db_host'))\\\n",
    "            .withColumn('node_ip', generate_db_ip_udf('db_host'))\\\n",
    "            .withColumn('node_attr', generate_db_attr_udf('columns', 'tables'))\\\n",
    "            .withColumn('ddn_id', lit('default_pii'))\\\n",
    "            .select(node_schema)\n",
    "db_node.toPandas()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the following block extracts storage node information\n",
    "# db_host_list = db_table_col.select('db_host')\\\n",
    "#                            .rdd.map(lambda row: row[0])\\\n",
    "#                            .collect()\n",
    "# def is_storage(ip):\n",
    "#     return ip in db_host_list\n",
    "# is_storage_udf = udf(is_storage, BooleanType())\n",
    "\n",
    "# storage_to_app = all_connections.filter(is_storage_udf('`id.orig_h`'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following block extracts application information\n",
    "application_cols = ['`id.orig_h`', '`id.orig_p`', '`id.resp_h`', '`id.resp_p`', 'application', 'proto', 'direction', 'total_bytes']\n",
    "\n",
    "known_applications = ['payroll', 'employee_info', 'customer', 'performance', 'sales']\n",
    "def extract_application_from_uri(uri):\n",
    "    if uri is None \\\n",
    "        or uri == '/' \\\n",
    "        or not uri.startswith('/'):\n",
    "        return 'unknown'\n",
    "    for known_app in known_applications:\n",
    "        if known_app in uri:\n",
    "            return known_app\n",
    "    tokens = uri.split('/')\n",
    "    return tokens[1]\n",
    "application_udf = udf(extract_application_from_uri, StringType())\n",
    "\n",
    "def get_app_direction_from_uri(uri, direction):\n",
    "    if 'set' in uri:\n",
    "        return 'co'\n",
    "    if 'check' in uri:\n",
    "        return 'counter'\n",
    "    return direction\n",
    "get_app_direction_from_uri_udf = udf(get_app_direction_from_uri, StringType())\n",
    "\n",
    "def in_web_list(ip):\n",
    "    return ip in web_portal\n",
    "in_web_list_udf = udf(in_web_list, BooleanType())\n",
    "\n",
    "def in_sql_list(ip):\n",
    "    return ip in sql_portal\n",
    "in_sql_list_udf = udf(in_sql_list, BooleanType())\n",
    "\n",
    "user_to_app = all_connections.filter(in_web_list_udf('`id.resp_h`'))\\\n",
    "                                 .withColumn('application', application_udf('uri'))\\\n",
    "                                 .withColumn('direction', get_app_direction_from_uri_udf('uri', 'direction'))\\\n",
    "                                 .select(application_cols)\\\n",
    "                                 .distinct().filter(col('application')!='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_gen_from_id(from_ip, port, application):\n",
    "    return from_ip + \":\" + port + '/' + application\n",
    "app_gen_from_id_udf = udf(app_gen_from_id, StringType())\n",
    "\n",
    "# currently this is a placeholder\n",
    "def generate_app_attr(ip):\n",
    "    res = {}\n",
    "    res['ip'] = ip\n",
    "    return json.dumps(res)\n",
    "generate_app_attr_udf = udf(generate_app_attr, StringType())\n",
    "\n",
    "app_node = user_to_app.withColumn('type', lit('application'))\\\n",
    "                      .withColumn('node_id', app_gen_from_id_udf('`id.resp_h`', '`id.resp_p`', 'application'))\\\n",
    "                      .withColumn('node_ip', col('`id.resp_h`'))\\\n",
    "                      .withColumn('node_attr', generate_app_attr_udf('`id.resp_h`'))\\\n",
    "                      .withColumn('ddn_id', lit('default_pii'))\\\n",
    "                      .select(node_schema)\\\n",
    "                      .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_node.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate app to storage edge\n",
    "\n",
    "def app_gen_from_id(from_ip, port, application):\n",
    "    return from_ip# + \":\" + port + '/' + application\n",
    "app_gen_from_id_udf = udf(app_gen_from_id, StringType())\n",
    "\n",
    "def app_gen_to_id(orig_ip):\n",
    "    return orig_ip\n",
    "app_gen_to_id_udf = udf(app_gen_to_id, StringType())\n",
    "\n",
    "# # this is a placeholder for application edge.\n",
    "# # currently it does NOT add any information\n",
    "# def app_gen_edge_attr(port, proto, total_bytes):\n",
    "#     res = {}\n",
    "#     res['port'] = port\n",
    "#     res['protocol'] = proto\n",
    "#     res['total_bytes'] = total_bytes\n",
    "#     return json.dumps(res)\n",
    "# app_gen_edge_attr_udf = udf(app_gen_edge_attr, StringType())\n",
    "\n",
    "app_to_db = all_connections.filter(in_sql_list_udf('`id.resp_h`'))\\\n",
    "                                 .withColumn('application', application_udf('uri'))\\\n",
    "                                 .select(application_cols)\\\n",
    "                                 .distinct()\n",
    "app_edge = app_to_db.withColumn('from_id', app_gen_from_id_udf('`id.orig_h`','`id.resp_p`','application'))\\\n",
    "                   .withColumn('to_id', app_gen_to_id_udf('`id.resp_h`'))\\\n",
    "                   .withColumn('ddn_id', lit('default_pii'))\\\n",
    "                   .select(edge_schema)\\\n",
    "                   .distinct()\n",
    "\n",
    "# all_connections.filter(in_sql_list_udf('`id.resp_h`'))\\\n",
    "#                 .filter(in_web_list_udf('`id.orig_h`'))\\\n",
    "#                 .withColumn('from_id', app_gen_from_id_udf('`id.orig_h`','`id.resp_p`','application'))\\\n",
    "#        .withColumn('to_id', app_gen_to_id_udf('`id.resp_h`'))\\\n",
    "#        .withColumn('edge_attr', app_gen_edge_attr_udf('`id.resp_p`', 'proto', 'total_bytes'))\\\n",
    "#        .withColumn('ddn_id', lit('default_pii'))\\\n",
    "#        .select(edge_schema)\\\n",
    "#        .distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following block add user information to all the connections\n",
    "# known_users = {\n",
    "#     '192.168.7.130' : 'arthur',\n",
    "#     '192.168.7.171' : 'hua'\n",
    "# }\n",
    "def add_user(ip):\n",
    "    return ip\n",
    "#     if ip in known_users:\n",
    "#         return known_users[ip]\n",
    "#     return 'unknown'\n",
    "add_user_udf = udf(add_user, StringType())\n",
    "all_connections_with_app = all_connections.withColumn('application', application_udf('uri'))\n",
    "user_df = all_connections_with_app.withColumn('user', add_user_udf('`id.orig_h`'))\\\n",
    "                                  .filter(~in_list_udf('`id.orig_h`'))\n",
    "#                         .filter(col('user')!='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_attr(ip, username):\n",
    "    res = {}\n",
    "    res['ip'] = ip\n",
    "    res['username'] = username\n",
    "    return json.dumps(res)\n",
    "generate_user_attr_udf = udf(generate_user_attr, StringType())\n",
    "\n",
    "user_node = user_df.withColumn('type', lit('user'))\\\n",
    "              .withColumn('node_id', col('user'))\\\n",
    "              .withColumn('node_ip', col('`id.orig_h`'))\\\n",
    "              .withColumn('node_attr', generate_user_attr_udf('`id.orig_h`', 'user'))\\\n",
    "              .withColumn('ddn_id', lit('default_pii'))\\\n",
    "              .select(node_schema).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_schema = ['category', 'node_id', 'node_ip', 'node_attr', 'ddn_id']\n",
    "# edge_schema = ['from_id', 'to_id', 'edge_attr', 'ddn_id']\n",
    "\n",
    "def user_gen_from_id(orig_ip):\n",
    "    return orig_ip\n",
    "user_gen_from_id_udf = udf(user_gen_from_id, StringType())\n",
    "\n",
    "def user_gen_to_id(resp_ip, port, application):\n",
    "    if application is not None and application != 'unknown':\n",
    "        return resp_ip + \":\" + port + '/' + application\n",
    "    return resp_ip\n",
    "user_gen_to_id_udf = udf(user_gen_to_id, StringType())\n",
    "\n",
    "# # this is a placeholder for user to application edge.\n",
    "# # currently it does NOT add any information\n",
    "# def user_gen_edge_attr(port, proto, total_bytes):\n",
    "#     res = {}\n",
    "#     ports = set()\n",
    "#     ports.add(port)\n",
    "    \n",
    "#     protos = set()\n",
    "#     protos.add(proto)\n",
    "    \n",
    "#     res['port'] = ports\n",
    "#     res['protocol'] = protos\n",
    "#     res['total_bytes'] = total_bytes\n",
    "#     return json.dumps(res)\n",
    "# user_gen_edge_attr_udf = udf(user_gen_edge_attr, StringType())\n",
    "\n",
    "user_edge = user_df.withColumn('from_id', user_gen_from_id_udf('`id.orig_h`'))\\\n",
    "       .withColumn('to_id', user_gen_to_id_udf('`id.resp_h`','`id.resp_p`','application'))\\\n",
    "       .withColumn('ddn_id', lit('default_pii'))\\\n",
    "       .select(edge_schema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_edges = nodes.filter(in_web_list_udf('node_ip'))\\\n",
    "     .withColumn('from_id', col('node_id'))\\\n",
    "     .withColumn('to_id', col('node_ip'))\\\n",
    "     .withColumn('direction', lit('same_machine'))\\\n",
    "     .withColumn('proto', lit('same_machine'))\\\n",
    "     .withColumn('ddn_id', lit('default_pii'))\\\n",
    "     .withColumn('application', lit('same_machine'))\\\n",
    "     .withColumn('total_bytes', lit(0)).select(edge_schema)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = app_node.union(user_node).union(db_node).union(web_nodes)\\\n",
    "        .withColumn('multi_home', multihomed_ip_udf('node_ip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_proto(proto):\n",
    "    if proto is None:\n",
    "        return 'con'\n",
    "    return proto\n",
    "gen_proto_udf = udf(gen_proto, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = user_edge.union(app_edge).union(same_edges)\\\n",
    "        .groupby('from_id', 'to_id', 'ddn_id', 'direction', 'proto')\\\n",
    "        .agg(sum('total_bytes').alias('total_bytes'))\\\n",
    "        .withColumn('proto', gen_proto_udf('proto'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = edges.filter(col('direction').isNotNull())\n",
    "def reorder_edge(row):\n",
    "    new_row = {}\n",
    "    if row['direction'] == 'counter':\n",
    "        new_row['from_id'] = row['to_id']\n",
    "        new_row['to_id'] = row['from_id']\n",
    "    else:\n",
    "        new_row['from_id'] = row['from_id']\n",
    "        new_row['to_id'] = row['to_id']\n",
    "    new_row['proto'] = row['proto']\n",
    "    new_row['total_bytes'] = row['total_bytes']\n",
    "    new_row['ddn_id'] = row['ddn_id']\n",
    "    return Row(**new_row)\n",
    "edges_new = edges.rdd.map(reorder_edge).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_connections.filter(col('`id.resp_h`') == '192.168.7.100')\\\n",
    "    .filter(col('`id.orig_h`') == '172.27.232.5')\\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_new.filter(col('from_id')=='192.168.7.100').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_from = edges_new.select('from_id').rdd.map(lambda row: row[0]).distinct().collect()\n",
    "edge_to = edges_new.select('to_id').rdd.map(lambda row: row[0]).distinct().collect()\n",
    "nodes_ip = nodes.select('node_ip').rdd.map(lambda row: row[0]).distinct().collect()\n",
    "# nodes_id = nodes.select('node_id').rdd.map(lambda row: row[0]).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_new.filter(col('proto')=='con').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ip = set(edge_from + edge_to + nodes_ip)\n",
    "len(all_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_map = {}\n",
    "all_ip = list(all_ip)\n",
    "for i in range(0, len(all_ip)):\n",
    "    ip_map[all_ip[i]] = i\n",
    "\n",
    "def map_ip(ip, second = None):\n",
    "    if second is None:\n",
    "        return ip_map[ip]\n",
    "    if ':80' in ip:\n",
    "        return ip_map[ip]\n",
    "    return ip_map[second]\n",
    "map_ip_udf = udf(map_ip, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'172.27.232.5': 7,\n",
       " '192.168.7.100': 21,\n",
       " '192.168.7.100:80/customer': 3,\n",
       " '192.168.7.100:80/employee_info': 16,\n",
       " '192.168.7.100:80/payroll': 2,\n",
       " '192.168.7.100:80/performance': 13,\n",
       " '192.168.7.100:80/sales': 15,\n",
       " '192.168.7.104': 11,\n",
       " '192.168.7.122': 6,\n",
       " '192.168.7.126': 17,\n",
       " '192.168.7.150': 10,\n",
       " '192.168.7.159': 9,\n",
       " '192.168.7.167': 18,\n",
       " '192.168.7.171': 1,\n",
       " '192.168.7.178': 5,\n",
       " '192.168.7.180': 0,\n",
       " '192.168.7.190': 19,\n",
       " '192.168.8.100': 12,\n",
       " '192.168.8.114': 14,\n",
       " '192.168.8.155': 4,\n",
       " '192.168.8.74': 20,\n",
       " '192.168.8.74:80/PIIFormTest': 8}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_final = nodes.withColumn('iid', map_ip_udf('node_id', 'node_ip'))\n",
    "edges_final = edges_new.withColumn('iid_from', map_ip_udf('from_id'))\\\n",
    "                    .withColumn('iid_to', map_ip_udf('to_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes.toPandas()\n",
    "nodes_final.drop('node_attr').repartition(1).write.mode('overwrite').option(\"header\", \"true\").csv('nodes.csv')\n",
    "edges_final.repartition(1).write.mode('overwrite').option(\"header\", \"true\").csv('edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddn_id</th>\n",
       "      <th>from_id</th>\n",
       "      <th>proto</th>\n",
       "      <th>to_id</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>iid_from</th>\n",
       "      <th>iid_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default_pii</td>\n",
       "      <td>192.168.7.100</td>\n",
       "      <td>con</td>\n",
       "      <td>172.27.232.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ddn_id        from_id proto         to_id  total_bytes  iid_from  \\\n",
       "0  default_pii  192.168.7.100   con  172.27.232.5          0.0        21   \n",
       "\n",
       "   iid_to  \n",
       "0       7  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_final.filter(col('from_id') == '192.168.7.100')\\\n",
    "            .filter(col('to_id') == '172.27.232.5')\\\n",
    "            .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_json = edges.toPandas().to_json()\n",
    "nodes_json = nodes.toPandas().to_json()\n",
    "ddn_dict = {}\n",
    "ddn_dict['nodes'] = nodes_json\n",
    "ddn_dict['edges'] = edges_json\n",
    "\n",
    "import json\n",
    "with open('ddn.json', 'w') as outfile:\n",
    "    json.dump(ddn_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_hash(from_id, to_id, ddn_id, application, direction):\n",
    "#     return from_id + to_id + ddn_id + application + direction\n",
    "# gen_hash_udf = udf(gen_hash, StringType())\n",
    "# def combine_edge(row1, row2):\n",
    "#     total_bytes1 = row1['total_bytes']\n",
    "#     total_bytes2 = row2['total_bytes']\n",
    "    \n",
    "#     total_bytes = total_bytes1 + total_bytes2\n",
    "    \n",
    "#     edge_attr1 = json.loads(row1['edge_attr'])\n",
    "#     edge_attr2 = json.loads(row2['edge_attr'])\n",
    "    \n",
    "#     new_attr = {}\n",
    "#     ports = set()\n",
    "#     ports.add(edge_attr1['port'])\n",
    "#     ports.add(edge_attr2['port'])\n",
    "    \n",
    "#     protos = set()\n",
    "#     protos.add(edge_attr1['protocol'])\n",
    "#     protos.add(edge_attr2['protocol'])\n",
    "    \n",
    "#     new_attr['port'] = list(ports)\n",
    "#     new_attr['protocol'] = list(protos)\n",
    "#     new_attr['total_bytes'] = total_bytes\n",
    "    \n",
    "#     new_row = {}\n",
    "#     new_row['from_id'] = row1['from_id']\n",
    "#     new_row['to_id'] = row1['to_id']\n",
    "#     new_row['edge_attr'] = json.dumps(new_attr)\n",
    "#     new_row['ddn_id'] = row1['ddn_id']\n",
    "#     new_row['direction'] = row1['direction']\n",
    "#     new_row['total_bytes'] = row1['total_bytes']\n",
    "#     return Row(**new_row)\n",
    "# edges_combined = edges.withColumn('hash', gen_hash_udf('from_id', 'to_id', 'ddn_id', 'application', 'direction'))\\\n",
    "#      .rdd.map(lambda row: (row['hash'], row))\\\n",
    "#      .reduceByKey(combine_edge).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFCCAYAAADGwmVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgwARb4DT6hBw0v0sKUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd55e1c0ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from_ = edges.select('from_id').rdd.map(lambda row: row[0]).collect()\n",
    "to_ = edges.select('to_id').rdd.map(lambda row: row[0]).collect()\n",
    "\n",
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Build a dataframe with 4 connections\n",
    "df = pd.DataFrame({ 'from': from_, 'to': to_})\n",
    "df\n",
    " \n",
    "# Build your graph\n",
    "G=nx.from_pandas_dataframe(df, 'from', 'to', create_using=nx.DiGraph())\n",
    " \n",
    "# Plot it\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py2neo.database.Transaction at 0x7fd558f00320>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py2neo import Graph\n",
    "\n",
    "graph = Graph(\"http://192.168.7.143:7474/db/data/\")\n",
    "\n",
    "# merge nodes and relationship\n",
    "# create Tom and Jerry as before\n",
    "u1 = Node(\"Person\",name='Tom',id=1)\n",
    "u2 = Node('Person', name='Jerry', id=2)\n",
    "\n",
    "# either use u1 and u2 directly\n",
    "u1_knows_u2 = Relationship(u1, 'KKNOWS', u2)\n",
    "graph.begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFromCSVtoNeo(graph):\n",
    "    query = \"MATCH (a {id: 21}),(b {id:14}) CREATE (a)-[r:tcp]->(b) RETURN a;\"\n",
    "    graph.run(query)\n",
    "importFromCSVtoNeo(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='192.168.7.143', port=8000): Max retries exceeded with url: /api/label/desc/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8cc5bc2e8>: Failed to establish a new connection: [Errno 111] Connection refused',))",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fc8cc5bc2e8>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='192.168.7.143', port=8000): Max retries exceeded with url: /api/label/desc/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8cc5bc2e8>: Failed to establish a new connection: [Errno 111] Connection refused',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-797b94fdb33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this block get label information from http request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://192.168.7.143:8000/api/label/desc/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Currently this is HARD CODED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mread_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='192.168.7.143', port=8000): Max retries exceeded with url: /api/label/desc/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc8cc5bc2e8>: Failed to establish a new connection: [Errno 111] Connection refused',))"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# this block get label information from http request\n",
    "r = requests.get('http://192.168.7.143:8000/api/label/desc/')\n",
    "\n",
    "# Currently this is HARD CODED\n",
    "if read_label:\n",
    "    label_map = {}\n",
    "    for labeljson in r.json():\n",
    "        apps = labeljson['address'].split(',')\n",
    "        label_map[labeljson['roles']] = list(apps)\n",
    "    label_map\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_ddn in label_map.keys():\n",
    "    print(new_ddn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_ddn_edge_from_app(cur_ddn, application):\n",
    "    for new_ddn in label_map.keys():\n",
    "        app_list = label_map[new_ddn]\n",
    "        if application in app_list:\n",
    "            return new_ddn\n",
    "    return cur_ddn\n",
    "label_ddn_edge_from_app_udf = udf(label_ddn_edge_from_app, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_labeled = edges.withColumn('ddn_id', \n",
    "                                 label_ddn_edge_from_app_udf('ddn_id', \n",
    "                                                             'application'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_node_labeled = app_node.drop('ddn_id')\\\n",
    "                           .join(edges_labeled, app_node.node_id == edges_labeled.from_id, 'left_outer')\\\n",
    "                           .select(node_schema)\n",
    "user_node_labeled = user_node.drop('ddn_id')\\\n",
    "                           .join(edges_labeled, user_node.node_id == edges_labeled.to_id, 'left_outer')\\\n",
    "                           .select(node_schema)\n",
    "db_node_labeled = db_node.drop('ddn_id')\\\n",
    "                           .join(edges_labeled, db_node.node_id == edges_labeled.to_id, 'left_outer')\\\n",
    "                           .select(node_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labeled = app_node_labeled.union(user_node_labeled)\\\n",
    "                               .union(db_node_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
